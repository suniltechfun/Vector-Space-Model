{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part2: Vector-space based IR System\n",
    "## Query Lookup\n",
    "### Objectives: \n",
    "#### 1. Load the saved the python dictionaries as pickle files to be used for query optimization.\n",
    "#### 2. Make the query using query lookup() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "from collections import Counter\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pickle\n",
    "from scipy import spatial\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the pickle files \n",
    "with open('documents_dict.pkl', 'rb') as documents_dict_handle:\n",
    "    documents_dict = pickle.load(documents_dict_handle)\n",
    "    \n",
    "with open('tf_idf_vector.pkl', 'rb') as tf_idf_vector_handle:\n",
    "    tf_idf_vector = pickle.load(tf_idf_vector_handle)\n",
    "    \n",
    "with open('bag_of_words.pkl', 'rb') as bag_of_words_handle:\n",
    "    bag_of_words = pickle.load(bag_of_words_handle)\n",
    "    \n",
    "with open('documents_title_dict.pkl', 'rb') as documents_title_dict_handle:\n",
    "    documents_title_dict = pickle.load(documents_title_dict_handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMART Notation used\n",
    "#### lnc.ltc(ddd.qqq)\n",
    "#### ltc ==> Logarithmic tf + IDF + Cosine Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate query vector\n",
    "def make_query_vector(documents_dict, bag_of_words, tokens):  \n",
    "    documents_count = len(documents_dict.keys())\n",
    "    all_tokens = list(bag_of_words.keys())\n",
    "\n",
    "    token_with_index = {}\n",
    "    for index, token in enumerate(all_tokens):\n",
    "        token_with_index[token] = index\n",
    "\n",
    "    query = np.zeros((len(all_tokens)))\n",
    "    query_counter = Counter(tokens)\n",
    "\n",
    "    # normalize\n",
    "    cnt = 0\n",
    "    for token in np.unique(tokens):\n",
    "        #Logarithmic tf \n",
    "        tf = 1 + np.log10(query_counter[token]+1)        \n",
    "        try:\n",
    "            df = bag_of_words[token]['df']\n",
    "        except:\n",
    "            df = 0\n",
    "        idf = np.log10((documents_count) / (df + 1))        \n",
    "        cnt += (tf * tf * idf * idf)        \n",
    "    cnt = np.sqrt(cnt)  \n",
    "    for token in np.unique(tokens):\n",
    "        tf = 1 + np.log10(query_counter[token]+1)\n",
    "        try:\n",
    "            df = bag_of_words[token]['df']\n",
    "        except:\n",
    "            df = 0\n",
    "        idf = np.log10((documents_count) / (df + 1))      \n",
    "        try:\n",
    "            # Cosine Normalization\n",
    "            query[token_with_index[token]] = (tf * idf) / cnt            \n",
    "        except:\n",
    "            pass\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for query lookup\n",
    "def query_lookup(query, documents_dict, tf_idf_vector, bag_of_words, documents_title_dict):\n",
    "    tokens = nltk.word_tokenize(query)\n",
    "\n",
    "    print(\"\\nQuery:\", query)\n",
    "    print(\"\\nTokens:\", tokens)\n",
    "\n",
    "    all_cosines = {}\n",
    "\n",
    "    query_vector = make_query_vector(documents_dict, bag_of_words, tokens)\n",
    "    \n",
    "    query_vector.sort() \n",
    "    print(query_vector[-10:]) \n",
    "    \n",
    "    #print(\"\\nQuery Vector: \" + str(query_vector.tolist()))\n",
    "    #print(\"\\nQuery Vector length:\", len(query_vector.tolist()))\n",
    "\n",
    "    for doc_id, doc_value in tf_idf_vector.items():\n",
    "        all_cosines[doc_id] = 1 - spatial.distance.cosine(query_vector, np.asarray(doc_value['tf_idf_vector']))\n",
    "\n",
    "    all_cosines_sorted = {k: v for k, v in sorted(all_cosines.items(), reverse=True, key=lambda item: item[1])}\n",
    "    all_cosines_sorted_counter = Counter(all_cosines_sorted)\n",
    "\n",
    "    # Finding Top K=10 documents\n",
    "    top_10_documents = all_cosines_sorted_counter.most_common(10)\n",
    "    print(top_10_documents)\n",
    "    for index, element in enumerate(top_10_documents):\n",
    "        title = documents_title_dict[element[0]]\n",
    "        print(\"Document:\", index + 1, \" Title:\", title, \" Score:\", element[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute the query as required ( This requires python dictionaries which needs to be in memory\n",
    "### We load the saved pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: Madalena is a former civil parish in the municipality of Tomar, Portugal\n",
      "\n",
      "Tokens: ['Madalena', 'is', 'a', 'former', 'civil', 'parish', 'in', 'the', 'municipality', 'of', 'Tomar', ',', 'Portugal']\n",
      "[0.         0.00237658 0.00320984 0.00411547 0.00478828 0.00958532\n",
      " 0.11030909 0.1620805  0.19991    0.22611323]\n",
      "[(2065119, 0.009485075072133475), (2058487, 0.007289733416690147), (2059316, 0.007289733416690147), (2060672, 0.007289733416690147), (2059854, 0.007289643218205244), (2055317, 0.007289609889421844), (2056349, 0.007289609889421844), (2056662, 0.007289609889421844), (2057762, 0.007289609889421844), (2057900, 0.007289609889421844)]\n",
      "Document: 1  Title: Madalena (Tomar)  Score: 0.009485075072133475\n",
      "Document: 2  Title: Subfund  Score: 0.007289733416690147\n",
      "Document: 3  Title: Gluggy  Score: 0.007289733416690147\n",
      "Document: 4  Title: Haruko  Score: 0.007289733416690147\n",
      "Document: 5  Title: T28  Score: 0.007289643218205244\n",
      "Document: 6  Title: Scienceworks  Score: 0.007289609889421844\n",
      "Document: 7  Title: VC1  Score: 0.007289609889421844\n",
      "Document: 8  Title: PZP  Score: 0.007289609889421844\n",
      "Document: 9  Title: Selar  Score: 0.007289609889421844\n",
      "Document: 10  Title: UDSD  Score: 0.007289609889421844\n"
     ]
    }
   ],
   "source": [
    "query ='Madalena is a former civil parish in the municipality of Tomar, Portugal'\n",
    "query_lookup(query, documents_dict, tf_idf_vector, bag_of_words, documents_title_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
